# 1.2 Gossip, Membership, and Grids

## Lesson 1: Gossip

### Multicast Problem

* In computer networking, multicast is group communication where data transmission is addressed to a group of destination computers simultaneously
* Multicast can be one-to-many or many-to-many distribution
* The difference between multicast and broadcast is that in broadcast, the packet is delivered to all the hosts connected to the network, whereas in multicast, the packet is delivered to intended recipients only.
* The multicast protocol typically sits at the application layer \(i.e., does not deal with the underlying network\)
* Challenges
  * Fault-Tolerance
    * Nodes may crash
    * Packets may be dropped
  * Scalability
    * Tens of thousands of nodes
* Simplest implementation: Centralized
  * The sender sends in a loop UDP/TCP packets
  * Problems
    * Not fault-tolerant: Sender may fail. Say it fails halfway through, only half of the receivers get the message
    * High overhead: Not scalable -&gt; high O\(N\) latency
* Solution: Tree-Based implementation
  * Pro: For a good \(balanced\) tree, the height is O\(log\(N\)\) -&gt; better latency
  * Con: High set up and maintenance costs
* Tree-Based multicast protocols
  * Build spanning trees to disseminate multicasts
  * Use ACKs or NAKs to repair multicasts not received
  * SRM: Scalable Reliable Multicast
    * Uses NAKs
    * Uses random delays \(before sending out repair request\) and exponential backoff \(if sending out multiple NAKs, doubles the wait time every time they wait\) to avoid NAK storms
  * RMTP: Reliable Multicast Transport Protocol
    * Uses ACKs
    * ACKs are only sent to designated receivers, which then re-transmit missing multicasts
* Studies show that despite these countermeasures, these protocols still suffer from O\(N\) ACK/NAK overheads, which motivated the development of gossip/epidemic protocols

### Gossip Protocols

* There are two "hyperparameters": t and b. Say we set t to be 5 seconds and b \(fan-out\) to be 2 nodes. In the following examples, we consider only 1 multicast message and only 1 sender.
* Periodically \(every t seconds\), a sender picks b random targets and sends them the multicast/gossip message. We can use UDP to transmit the messages as the gossip protocol itself is very reliable.
* Once a node receives its gossip, it is said to be "infected" and becomes a sender. 
* The gossip protocol is not synchronized across nodes: each node uses its local clock to send messages in rounds. When doing analyses, we typically assume them to be synchronized, though.
* Those above described the "push" gossip: once you have a multicast message, you start gossiping about it.
  * There is also a "pull" gossip that periodically polls randomly selected processes for new multicast messages that haven't been received. 
  * Another variant is the push-pull model. In this model, when sending out a pull query, the sender also includes some gossip messages it received recently.
* Multiple messages -&gt; push a random subset/recently-received ones/high-priority ones

![In this example, we start with one sender at the bottom left corner](../../.gitbook/assets/screen-shot-2021-06-28-at-7.29.07-am.png)

### Gossip Analysis

* The simple push protocol:
  * Is lightweight in large groups
  * Spreads a multicast quickly
  * Is highly fault-tolerant
* Analyze using Epidemiology
  * Population: \(n+1\) nodes
  * The contact rate between any individual pair is ÃŸ
  * At any time, each individual is either uninfected \(x\) or infected \(y\)
  * x\_0 = n, y\_0 = 1. At all times, x + y = n + 1
* Model as continuous time process. Do some math, and the conclusion is that when t becomes very large \(as time progresses\), x goes to 0, and y goes to n + 1. I.e., eventually, everyone receives the gossip. We can also show that the gossip protocol is fast: it converges within a logarithmic number of rounds.
* Recap
  * Lightweight: Each node transmits no more than cblog\(n\) gossip messages
  * Low latency: Converges within clog\(n\) rounds
  * Reliability: All but 1/\(n^\(cb-2\)\) nodes receive the multicast
* While log\(n\) is not constant, it grows very slowly pragmatically \(e.g., using base = 2, log\(1000\) ~= 10, log\(all IPv4 addresses\) = 32\).
* Packet loss: with 50% packet loss, analyze with b /= 2. To achieve the same reliability as 0% loss rate, take twice as many rounds
* Node failure: with 50% nodes failing, analyze with n /= 2 and b /= 2. Same as above
* Fault tolerance: with failures, it is possible \(but improbable\) that the epidemic dies out quickly. If it happens, it happens early, but as gossips spread very fast, it is very difficult to kill a gossip after a few rounds \(just like pandemics like COVID-19/rumors on the internet!\)
* In all forms of a gossip, it takes O\(log\(n\)\) rounds before n/2 nodes get the gossip \(because the fastest structure for a message to spread is a spanning tree\). Thereafter, pull gossip is faster than push gossip. The second half of pull gossip finishes in time O\(log\(log\(n\)\)\). Some more math is involved here...
* Gossip protocols are not topology-aware -&gt; core switches may get overloaded \(O\(n\)\). \(TODO: add pic here\). In this example, there are two subnets/racks. If nodes select targets randomly, half of the gossips will go through the router. The fix is to have gossips prefer nodes in the local subnet using a higher probability and vice versa. E.g., in subnet i with n\_i nodes, pick gossip target in the subnet with probability \(1 - 1/n\_i\). With this fix, the router load becomes O\(1\), and the dissemination time is still O\(log\(n\)\).

### Gossip Implementations

* Some implementations

    TODO: Add pic here

* Example: NNTP Inter-Server Protocol
  * TODO: Add pic here

