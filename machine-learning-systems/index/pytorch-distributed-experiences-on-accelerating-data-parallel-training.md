# PyTorch Distributed: Experiences on Accelerating Data Parallel Training

