# Table of contents

* [Rui's Blog/Paper Reading Notes - Introduction](README.md)

## Personal Blog <a href="#blog" id="blog"></a>

* [Personal Blog - Index](blog/blog-index/README.md)
  * [How to Create Picture-in-Picture Effect / Video Overlay for a Presentation Video](blog/blog-index/how-to-create-picture-in-picture-effect-video-overlay-for-a-presentation-video.md)
  * [How to Do Your Part to Protect the Environment in Wisconsin](blog/blog-index/how-to-do-your-part-to-protect-the-environment-in-wisconsin.md)
  * [How to Get a Driver's License in Wisconsin](blog/blog-index/how-to-get-a-drivers-license-in-wisconsin.md)
  * [How to Travel from the U.S. to China onboard AA127 in June 2021](blog/blog-index/aa127-hui-guo-ji.md)
  * [How to Transfer Credits Back to UW-Madison](blog/blog-index/how-to-transfer-credits-back-to-uw-madison.md)
* [Towards applying to CS Ph.D. programs](blog/towards-applying-to-cs-ph.d.-programs.md)

## Machine Learning Systems

* [Machine Learning Systems - Index](machine-learning-systems/machine-learning-systems-index/README.md)
  * [\[2011 NSDI\] Dominant Resource Fairness: Fair Allocation of Multiple Resource Types](machine-learning-systems/machine-learning-systems-index/dominant-resource-fairness-fair-allocation-of-multiple-resource-types.md)
  * [\[2014 OSDI\] Scaling Distributed Machine Learning with the Parameter Server](machine-learning-systems/machine-learning-systems-index/scaling-distributed-machine-learning-with-the-parameter-server.md)
  * [\[2018 OSDI\] Gandiva: Introspective Cluster Scheduling for Deep Learning](machine-learning-systems/machine-learning-systems-index/gandiva-introspective-cluster-scheduling-for-deep-learning.md)
  * [\[2018 SIGCOMM\] Chameleon: Scalable Adaptation of Video Analytics via Temporal and Cross-camera ...](machine-learning-systems/machine-learning-systems-index/2018-sigcomm-chameleon-scalable-adaptation-of-video-analytics-via-temporal-and-cross-camera-....md)
  * [\[2018 NIPS\] Dynamic Space-Time Scheduling for GPU Inference](machine-learning-systems/machine-learning-systems-index/2018-nips-dynamic-space-time-scheduling-for-gpu-inference.md)
  * [\[2019 ATC\] Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training Workloads](machine-learning-systems/machine-learning-systems-index/analysis-of-large-scale-multi-tenant-gpu-clusters-for-dnn-training-workloads.md)
  * [\[2019 NSDI\] Tiresias: A GPU Cluster Manager for Distributed Deep Learning](machine-learning-systems/machine-learning-systems-index/tiresias-a-gpu-cluster-manager-for-distributed-deep-learning.md)
  * [\[2019 SOSP\] ByteScheduler: A Generic Communication Scheduler for Distributed DNN Training ...](machine-learning-systems/machine-learning-systems-index/2019-sosp-bytescheduler-a-generic-communication-scheduler-for-distributed-dnn-training-....md)
  * [\[2019 SOSP\] PipeDream: Generalized Pipeline Parallelism for DNN Training](machine-learning-systems/machine-learning-systems-index/pipedream-generalized-pipeline-parallelism-for-dnn-training.md)
  * [\[2019 NIPS\] GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism](machine-learning-systems/machine-learning-systems-index/gpipe-efficient-training-of-giant-neural-networks-using-pipeline-parallelism.md)
  * [\[2019 SC\] ZeRO: memory optimizations toward training trillion parameter models](machine-learning-systems/machine-learning-systems-index/2019-sc-zero-memory-optimizations-toward-training-trillion-parameter-models.md)
  * [\[2020 OSDI\] Gavel: Heterogeneity-Aware Cluster Scheduling Policies for Deep Learning Workloads](machine-learning-systems/machine-learning-systems-index/gavel-heterogeneity-aware-cluster-scheduling-policies-for-deep-learning-workloads.md)
  * [\[2020 OSDI\] BytePS: A High Performance and Generic Framework for Distributed DNN Training](machine-learning-systems/machine-learning-systems-index/byteps-a-high-performance-and-generic-framework-for-distributed-dnn-training.md)
  * [\[2020 SIGCOMM\] Reducto: On-Camera Filtering for Resource-Efficient Real-Time Video Analytics](machine-learning-systems/machine-learning-systems-index/2020-sigcomm-reducto-on-camera-filtering-for-resource-efficient-real-time-video-analytics/README.md)
    * [\[2020 MLSys\] Salus: Fine-Grained GPU Sharing Primitives for Deep Learning Applications](machine-learning-systems/machine-learning-systems-index/2020-sigcomm-reducto-on-camera-filtering-for-resource-efficient-real-time-video-analytics/salus-fine-grained-gpu-sharing-primitives-for-deep-learning-applications.md)
  * [\[2020 EuroSys\] AlloX: Compute Allocation in Hybrid Clusters](machine-learning-systems/machine-learning-systems-index/allox-compute-allocation-in-hybrid-clusters.md)
  * [\[2020 VLDB\] PyTorch Distributed: Experiences on Accelerating Data Parallel Training](machine-learning-systems/machine-learning-systems-index/pytorch-distributed-experiences-on-accelerating-data-parallel-training.md)
  * [\[2020 NetAI\] Is Network the Bottleneck of Distributed Training?](machine-learning-systems/machine-learning-systems-index/2020-netai-is-network-the-bottleneck-of-distributed-training.md)
  * [\[2020 NSDI\] Themis: Fair and Efficient GPU Cluster Scheduling](machine-learning-systems/machine-learning-systems-index/themis-fair-and-efficient-gpu-cluster-scheduling.md)
  * [\[2021 MLSys\] Accordion: Adaptive Gradient Communication via Critical Learning Regime Identification](machine-learning-systems/machine-learning-systems-index/accordion-adaptive-gradient-communication-via-critical-learning-regime-identification.md)
  * [\[2021 VLDB\] Analyzing and Mitigating Data Stalls in DNN Training](machine-learning-systems/machine-learning-systems-index/analyzing-and-mitigating-data-stalls-in-dnn-training.md)
  * [\[2021 FAST\] CheckFreq: Frequent, Fine-Grained DNN Checkpointing](machine-learning-systems/machine-learning-systems-index/checkfreq-frequent-fine-grained-dnn-checkpointing.md)
  * [\[2021 EuroMLSys\] Interference-Aware Scheduling for Inference Serving](machine-learning-systems/machine-learning-systems-index/2021-euromlsys-interference-aware-scheduling-for-inference-serving.md)
  * [\[2021 OSDI\] Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning](machine-learning-systems/machine-learning-systems-index/pollux-co-adaptive-cluster-scheduling-for-goodput-optimized-deep-learning.md)
  * [\[2021 MLSys\] Wavelet: Efficient DNN Training with Tick-Tock Scheduling](machine-learning-systems/machine-learning-systems-index/wavelet-efficient-dnn-training-with-tick-tock-scheduling.md)
  * [\[2021 NSDI\] SwitchML: Scaling Distributed Machine Learning with In-Network Aggregation](machine-learning-systems/machine-learning-systems-index/2021-nsdi-switchml-scaling-distributed-machine-learning-with-in-network-aggregation.md)
* [Big Data Systems - Index](machine-learning-systems/index/README.md)
  * [\[2003 SOSP\] The Google File System](machine-learning-systems/index/the-google-file-system.md)
  * [\[2004 OSDI\] MapReduce: Simplified Data Processing on Large Clusters](machine-learning-systems/index/mapreduce-simplified-data-processing-on-large-clusters.md)
  * [\[2010 SIGMOD\] Pregel: A System for Large-Scale Graph Processing](machine-learning-systems/index/pregel-a-system-for-large-scale-graph-processing.md)
  * [\[2011 NSDI\] Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center](machine-learning-systems/index/mesos-a-platform-for-fine-grained-resource-sharing-in-the-data-center.md)
  * [\[2012 NSDI\] Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster ...](machine-learning-systems/index/resilient-distributed-datasets-a-fault-tolerant-abstraction-for-in-memory-cluster-computing.md)
  * [\[2012 OSDI\] PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs](machine-learning-systems/index/powergraph-distributed-graph-parallel-computation-on-natural-graphs.md)
  * [\[2019 FAST\] DistCache: Provable Load Balancing for Large-Scale Storage Systems with Distributed...](machine-learning-systems/index/2019-fast-distcache-provable-load-balancing-for-large-scale-storage-systems-with-distributed....md)
  * [\[2021 HotOS\] From Cloud Computing to Sky Computing](machine-learning-systems/index/from-cloud-computing-to-sky-computing.md)
  * [\[2021 EuroSys\] NextDoor: Accelerating graph sampling for graph machine learning using GPUs](machine-learning-systems/index/accelerating-graph-sampling-for-graph-machine-learning-using-gpus.md)

## Earlier Readings & Notes

* [High Performance Computing Course Notes](earlier-readings-and-notes/cs759-hpc-course-notes/README.md)
  * [Lecture 1: Course Overview](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-1-course-overview.md)
  * [Lecture 2: From Code to Instructions. The FDX Cycle. Instruction Level Parallelism.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-2-from-code-to-instructions.-the-fdx-cycle.-instruction-level-parallelism..md)
  * [Lecture 3: Superscalar architectures. Measuring Computer Performance. Memory Aspects.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-3-superscalar-architectures.-measuring-computer-performance.-memory-aspects..md)
  * [Lecture 4: The memory hierarchy. Caches.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-4-the-memory-hierarchy.-caches..md)
  * [Lecture 5: Caches, wrap up. Virtual Memory.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-5-caches-wrap-up.-virtual-memory..md)
  * [Lecture 6: The Walls to Sequential Computing. Moore’s Law.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-6-the-walls-to-sequential-computing.-moores-law..md)
  * [Lecture 7: Parallel Computing. Flynn's Taxonomy. Amdahl's Law.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-8-parallel-computing.-flynns-taxonomy.-amdahls-law..md)
  * [Lecture 8: GPU Computing Intro. The CUDA Programming Model. CUDA Execution Configuration.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-8-gpu-computing-intro.-the-cuda-programming-model.-cuda-execution-configuration.md)
  * [Lecture 9: GPU Memory Spaces](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-9.md)
  * [Lecture 10: GPU Scheduling Issues.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-10-gpu-scheduling-issues..md)
  * [Lecture 11: Execution Divergence. Control Flow in CUDA. CUDA Shared Memory Issues.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-11-execution-divergence.-control-flow-in-cuda.-global-memory-access-patterns-and.md)
  * [Lecture 12: Global Memory Access Patterns and Implications.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-12-cuda-shared-memory-issues..md)
  * [Lecture 13: Atomic operations in CUDA. GPU ode optimization rules of thumb.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-12-cuda-shared-memory-issues.-atomic-operations-in-cuda..md)
  * [Lecture 14: CUDA Case Studies. (1) 1D Stencil Operation. (2) Vector Reduction in CUDA.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-14-tiling-as-a-programing-pattern-in-cuda.-example-vector-reduction-in-cuda..md)
  * [Lecture 15: CUDA Case Studies. (3) Parallel Prefix Scan on the GPU. Using Multiple Streams in CUDA.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-15-cuda-optimization-issues.-resource-utilization-issues.-parallel-prefix-scan-on-the-gpu..md)
  * [Lecture 16: Streams, and overlapping data copy with execution.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-16-streams-and-overlapping-data-copy-with-execution..md)
  * [Lecture 17: GPU Computing: Advanced Features.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-17-gpu-computing-advanced-features.-unified-memory-usage..md)
  * [Lecture 18: GPU Computing with thrust and cub.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-18-gpu-computing-with-thrust-and-cub..md)
  * [Lecture 19: Hardware aspects relevant in multi-core, shared memory parallel computing.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-19-hardware-aspects-relevant-in-multi-core-shared-memory-parallel-computing..md)
  * [Lecture 20: Multi-core Parallel Computing with OpenMP. Parallel Regions.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-20-multi-core-parallel-computing-with-openmp.-parallel-regions..md)
  * [Lecture 21: OpenMP Work Sharing.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-21-openmp-work-sharing..md)
  * [Lecture 22: OpenMP Work Sharing](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-22-openmp-work-sharing.md)
  * [Lecture 23: OpenMP NUMA Aspects. Caching and OpenMP.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-23-openmp-numa-aspects.-caching-and-openmp..md)
  * [Lecture 24: Critical Thinking. Code Optimization Aspects.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-24-critical-thinking.-code-optimizatino-aspects..md)
  * [Lecture 25: Computing with Supercomputers.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-25-computing-with-supercomputers..md)
  * [Lecture 26: MPI Parallel Programming General Introduction. Point-to-Point Communication.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-26-mpi-parallel-programming-general-introduction.-point-to-point-communication..md)
  * [Lecture 27: MPI Parallel Programming Point-to-Point communication: Blocking vs. Non-blocking sends.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-27-mpi-parallel-programming-point-to-point-communication-blocking-vs.-non-blocking-sends..md)
  * [Lecture 28: MPI Parallel Programming: MPI Collectives. Overview of topics covered in the class.](earlier-readings-and-notes/cs759-hpc-course-notes/lecture-28-mpi-parallel-programming-mpi-collectives.-overview-of-topics-covered-in-the-class..md)
* [Cloud Computing Course Notes](earlier-readings-and-notes/cloud-computing-course-notes/README.md)
  * [1.1 Introduction to Clouds, MapReduce](earlier-readings-and-notes/cloud-computing-course-notes/1.1-introduction-to-clouds-mapreduce.md)
  * [1.2 Gossip, Membership, and Grids](earlier-readings-and-notes/cloud-computing-course-notes/1.2-gossip-membership-and-grids.md)
  * [1.3 P2P Systems](earlier-readings-and-notes/cloud-computing-course-notes/1.3-p2p-systems.md)
  * [1.4 Key-Value Stores, Time, and Ordering](earlier-readings-and-notes/cloud-computing-course-notes/1.4-key-value-stores-time-and-ordering.md)
  * [1.5 Classical Distributed Algorithms](earlier-readings-and-notes/cloud-computing-course-notes/1.5-classical-distributed-algorithms.md)
  * [4.1 Spark, Hortonworks, HDFS, CAP](earlier-readings-and-notes/cloud-computing-course-notes/4.1-spark-hortonworks-hdfs-cap.md)
  * [4.2 Large Scale Data Storage](earlier-readings-and-notes/cloud-computing-course-notes/4.2-large-scale-data-storage.md)
* [Operating Systems Papers - Index](earlier-readings-and-notes/index/README.md)
  * [CS 736 @ UW-Madison Fall 2020 Reading List](earlier-readings-and-notes/index/cs-736-uw-madison-fall-2020-reading-list.md)
  * [All File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent Applications](earlier-readings-and-notes/index/all-file-systems-are-not-created-equal-on-the-complexity-of-crafting-crash-consistent-applications.md)
  * [ARC: A Self-Tuning, Low Overhead Replacement Cache](earlier-readings-and-notes/index/arc-a-self-tuning-low-overhead-replacement-cache.md)
  * [A File is Not a File: Understanding the I/O Behavior of Apple Desktop Applications](earlier-readings-and-notes/index/a-file-is-not-a-file-understanding-the-i-o-behavior-of-apple-desktop-applications.md)
  * [Biscuit: The benefits and costs of writing a POSIX kernel in a high-level language](earlier-readings-and-notes/index/biscuit-the-benefits-and-costs-of-writing-a-posix-kernel-in-a-high-level-language.md)
  * [Data Domain: Avoiding the Disk Bottleneck in the Data Domain Deduplication File System](earlier-readings-and-notes/index/data-domain-avoiding-the-disk-bottleneck-in-the-data-domain-deduplication-file-system.md)
  * [Disco: Running Commodity Operating Systems on Scalable Multiprocessors](earlier-readings-and-notes/index/disco-running-commodity-operating-systems-on-scalable-multiprocessors.md)
  * [FFS: A Fast File System for UNIX](earlier-readings-and-notes/index/ffs-a-fast-file-system-for-unix.md)
  * [From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees](earlier-readings-and-notes/index/from-wisckey-to-bourbon-a-learned-index-for-log-structured-merge-trees.md)
  * [LegoOS: A Disseminated, Distributed OS for Hardware Resource Disaggregation](earlier-readings-and-notes/index/legoos-a-disseminated-distributed-os-for-hardware-resource-disaggregation.md)
  * [LFS: The Design and Implementation of a Log-Structured File System](earlier-readings-and-notes/index/lfs-the-design-and-implementation-of-a-log-structured-file-system.md)
  * [Lottery Scheduling: Flexible Proportional-Share Resource Management](earlier-readings-and-notes/index/lottery-scheduling-flexible-proportional-share-resource-management.md)
  * [Memory Resource Management in VMware ESX Server](earlier-readings-and-notes/index/memory-resource-management-in-vmware-esx-server.md)
  * [Monotasks: Architecting for Performance Clarity in Data Analytics Frameworks](earlier-readings-and-notes/index/monotasks-architecting-for-performance-clarity-in-data-analytics-frameworks.md)
  * [NFS: Sun's Network File System](earlier-readings-and-notes/index/nfs-suns-network-file-system.md)
  * [OptFS: Optimistic Crash Consistency](earlier-readings-and-notes/index/optfs-optimistic-crash-consistency.md)
  * [RAID: A Case for Redundant Arrays of Inexpensive Disks](earlier-readings-and-notes/index/raid-a-case-for-redundant-arrays-of-inexpensive-disks.md)
  * [RDP: Row-Diagonal Parity for Double Disk Failure Correction](earlier-readings-and-notes/index/rdp-row-diagonal-parity-for-double-disk-failure-correction.md)
  * [Resource Containers: A New Facility for Resource Management in Server Systems](earlier-readings-and-notes/index/resource-containers-a-new-facility-for-resource-management-in-server-systems.md)
  * [ReVirt: Enabling Intrusion Analysis through Virtual-Machine Logging and Replay](earlier-readings-and-notes/index/revirt-enabling-intrusion-analysis-through-virtual-machine-logging-and-replay.md)
  * [Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism](earlier-readings-and-notes/index/scheduler-activations-effective-kernel-support-for-the-user-level-management-of-parallelism.md)
  * [SnapMirror: File-System-Based Asynchronous Mirroring for Disaster Recovery](earlier-readings-and-notes/index/snapmirror-file-system-based-asynchronous-mirroring-for-disaster-recovery.md)
  * [The Linux Scheduler: a Decade of Wasted Cores](earlier-readings-and-notes/index/the-linux-scheduler-a-decade-of-wasted-cores.md)
  * [The Unwritten Contract of Solid State Drives](earlier-readings-and-notes/index/the-unwritten-contract-of-solid-state-drives.md)
  * [Venti: A New Approach to Archival Storage](earlier-readings-and-notes/index/venti-a-new-approach-to-archival-storage.md)
* [Soccer Analytics Papers - Index](earlier-readings-and-notes/soccer-analytics-index/README.md)
  * [Merging Pose And Contextual Data To Estimate Orientation Of Soccer Players](earlier-readings-and-notes/soccer-analytics-index/merging-pose-and-contextual-data-to-estimate-orientation-of-soccer-players.md)
  * [Soccer analytics: Unravelling the complexity of “the beautiful game”](earlier-readings-and-notes/soccer-analytics-index/soccer-analytics-unravelling-the-complexity-of-the-beautiful-game.md)
  * [Using Player’s Body-Orientation to Model Pass Feasibility in Soccer](earlier-readings-and-notes/soccer-analytics-index/using-players-body-orientation-to-model-pass-feasibility-in-soccer.md)
* [Earlier Notes](earlier-readings-and-notes/earlier-notes/README.md)
  * [How to read a paper](earlier-readings-and-notes/earlier-notes/how-to-read-a-paper.md)
  * [An Incomplete Guide to GPU Profiling](earlier-readings-and-notes/earlier-notes/an-incomplete-guide-to-gpu-profiling.md)
  * [Common Issues (& Fixes) when Playing with GPUs](earlier-readings-and-notes/earlier-notes/common-issues-and-fixes-when-playing-with-gpus.md)

## FIXME

* [Template for Paper Reading Notes](fixme/template.md)
